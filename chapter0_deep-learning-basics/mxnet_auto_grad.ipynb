{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from copy import copy\n",
    "\n",
    "from mxnet import autograd, nd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 自动求梯度\n",
    "\n",
    "\n",
    "在深度学习中，我们经常需要对函数求梯度。mxnet提供的autograd模块，可用于自动求解梯度。\n",
    "\n",
    "以求解函数 $$ y = 2x^Tx $$ 的梯度为例"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 2.]\n",
      " [-4.]\n",
      " [-2.]\n",
      " [ 3.]]\n",
      "<NDArray 4x1 @cpu(0)>\n",
      "None\n",
      "\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "<NDArray 4x1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 随机生成变量x\n",
    "x = nd.random.randint(-4, 5, shape=(4, 1)).astype(float)\n",
    "print(x)\n",
    "\n",
    "\n",
    "# 调用attach_grad函数，申请存储梯度所需要的内存。\n",
    "print(x.grad)\n",
    "x.attach_grad()\n",
    "\n",
    "# 初始化梯度为0\n",
    "print(x.grad)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:未调用record函数，求梯度报错\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[  8.]\n",
      " [-16.]\n",
      " [ -8.]\n",
      " [ 12.]]\n",
      "<NDArray 4x1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 默认条件下mxnet不会记录用于求梯度的计算，需要调用record函数来要求mxnet记录与梯度有关的计算\n",
    "with autograd.record():\n",
    "    y = 2 * nd.dot(x.T, x)\n",
    "\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "\n",
    "\n",
    "# 如果没有调用record函数，\n",
    "x_new = copy(x)\n",
    "y_new = 2 * nd.dot(x_new.T, x_new)\n",
    "\n",
    "try:\n",
    "    y_new.backward()\n",
    "except Exception as e:\n",
    "    logging.error('未调用record函数，求梯度报错')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 在调用record函数后，mxnet不仅会记录并计算梯度，还会将运行模式从预测模式转为训练模式\n",
    "print(autograd.is_training())\n",
    "with autograd.record():\n",
    "    print(autograd.is_training())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### 对python控制流求梯度\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0.75617343]]\n",
      "<NDArray 1x1 @cpu(0)>\n",
      "\n",
      "[[1548.64318848]]\n",
      "<NDArray 1x1 @cpu(0)>\n",
      "\n",
      "[[2048.]]\n",
      "<NDArray 1x1 @cpu(0)>\n",
      "\n",
      "[[1.]]\n",
      "<NDArray 1x1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 自定义函数 f\n",
    "def f(a):\n",
    "\n",
    "    b = a * 2\n",
    "    while b.norm().asscalar() < 1000:\n",
    "        b = b * 2\n",
    "\n",
    "    if b.sum().asscalar() > 0:\n",
    "        return b\n",
    "    else:\n",
    "        return 100 * b\n",
    "\n",
    "# 求自定义函数 f 的梯度\n",
    "n = 1\n",
    "for i in range(n):\n",
    "    x = nd.random.normal(shape=(1, 1)).astype(float)\n",
    "    print(x)\n",
    "\n",
    "    x.attach_grad()\n",
    "    with autograd.record():\n",
    "        y = f(x)\n",
    "    print(y)\n",
    "    y.backward()\n",
    "\n",
    "    print(x.grad)\n",
    "    print(x.grad == y/x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 头梯度\n",
    "\n",
    "z = f(y), y = g(x), 则有 dz/dx = dz/dy * dy/dx，此时可以先计算函数f的梯度，再在g的基础上乘上f的梯度。\n",
    "此时引入头梯度,头梯度相当于在函数梯度前提供一个需要乘上的系数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[  4.  32.]\n",
      " [108. 256.]]\n",
      "<NDArray 2x2 @cpu(0)>\n",
      "\n",
      "[[  4.  32.]\n",
      " [108. 256.]]\n",
      "<NDArray 2x2 @cpu(0)>\n",
      "\n",
      "[[40.         32.        ]\n",
      " [10.80000016  2.55999994]]\n",
      "<NDArray 2x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 没有头梯度\n",
    "x = nd.array([[1, 2], [3, 4]]).astype(float)\n",
    "x.attach_grad()\n",
    "with autograd.record():\n",
    "    y = x * x\n",
    "    z = y * x * x\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "\n",
    "\n",
    "# 头梯度全为1\n",
    "x = nd.array([[1, 2], [3, 4]]).astype(float)\n",
    "x.attach_grad()\n",
    "with autograd.record():\n",
    "    y = x * x\n",
    "    z = y * x * x\n",
    "\n",
    "head_gradient = nd.array([[1, 1], [1, 1]]).astype(float)\n",
    "z.backward(head_gradient)\n",
    "print(x.grad)\n",
    "\n",
    "\n",
    "# 设置头梯度\n",
    "x = nd.array([[1, 2], [3, 4]]).astype(float)\n",
    "x.attach_grad()\n",
    "with autograd.record():\n",
    "    y = x * x\n",
    "    z = y * x * x\n",
    "\n",
    "head_gradient = nd.array([[10, 1], [0.1, 0.01]]).astype(float)\n",
    "z.backward(head_gradient)\n",
    "print(x.grad)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}